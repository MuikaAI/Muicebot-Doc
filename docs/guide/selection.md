# 模型选型指南

近些年来，随着 LLM 训练规模和参数的不断扩大，大语言模型性能发生着翻天覆地的变化，与此同时，涌现出了非常多优秀的模型，在各个领域发挥着卓越的性能。

但是，不同参数的语言模型在角色扮演任务上仍然显现出巨大的差异，本文将从模型参数、模型系列两方面向您介绍如何选择最合适的模型。

## Muicebot 建议模型

总而言之，

对于 `Muice.jinja2` 和 `Muika.jinja2` 人设模板，建议选择: `qwen3-30b-a3b` 或更小参数的模型；

对于嵌入任务，建议选择阿里云百炼平台的 `text-embedding-v4` 嵌入模型。

## 小小的也很可爱

先说结论，对于一般角色扮演任务，优先选择参数量较小的语言模型，如 `qwen3-30b-a3b`，而参数量较大的模型容易出现幻觉，更容易脱离现实中的对话语境。

以下的例子演示了较大参数的模型如何影响最终输出:

| qwen3-235b-a22b                                                                                                    |
| ------------------------------------------------------------------------------------------------------------------ |
| **提示:** _晚上好雪_                                                                                               |
| **模型回复:** _晚上好呀～星星都在眨眼睛了呢！你在做什么呀？我刚刚泡了杯热可可，暖暖的超舒服！要不要一起看会月亮？_ |
| **提示:** _现在已经是下午了（）_                                                                                   |
| **模型回复:** _哎呀抱歉啦～太阳还在值班呢！要一起喝下午茶吗？我刚烤了小饼干哦！_                                   |

这样的对话难以让用户产生沉浸感，让我们选择更低参数量的 `qwen3-30b-a3b` 看看：

| qwen3-30b-a3b                                                                         |
| ------------------------------------------------------------------------------------- |
| **提示:** _晚上好雪_                                                                  |
| **模型回复:** _晚上好呀～沐沐大人今天过得怎么样呀？(•̀ᴗ•́)و_                            |
| **提示:** _现在已经是下午了（）_                                                      |
| **模型回复:** _诶？那可不行呢！要不我们一起来做点有趣的事，让精神好起来吧～(๑•̀ㅂ•́)و✧_ |

尽管这与理想语气还有很大差异，但上面的对话已经让人拥有想要继续聊下去的欲望，而不是沉浸在幻觉中的月亮和小饼干。

\*对于 Qwen3 系列模型，以上的对话关闭了思考模式，同样的，诸如 Deepseek-R1 此类的思考模型也会带来强烈的幻觉影响。为了成本和效果考虑，建议优先选择可关闭思考模式的模型，具体原因此处不再赘述。

## 更适合中国互联网语境的系列模型

字面意思，你应该选择国内厂商的模型而非国外厂商的模型，因为国内厂商他们拥有更多中国互联网语境的对话数据。不用说你都知道，不应该使用 `Gemini 2.5 Pro` 作为角色扮演的模型。

建议选择 `Qwen` 系列的模型，`GPT4` 次之，最近兴起的 `Kimi` 系列模型也可以值得考虑。

同样地，让我们来看看 `Qwen` 模型和 `Gemini` 模型在回答风格上的差异。

| qwen3-30b-a3b                                                                         |
| ------------------------------------------------------------------------------------- |
| **提示:** _晚上好雪_                                                                  |
| **模型回复:** _晚上好呀～沐沐大人今天过得怎么样呀？(•̀ᴗ•́)و_                            |
| **提示:** _现在已经是下午了（）_                                                      |
| **模型回复:** _诶？那可不行呢！要不我们一起来做点有趣的事，让精神好起来吧～(๑•̀ㅂ•́)و✧_ |

和上面的一样，我们就不再说了。现在看看 `Gemini 2.5`

| gemini-2.5-flash                                                                                                                 |
| -------------------------------------------------------------------------------------------------------------------------------- |
| **提示:** _晚上好_                                                                                                               |
| **模型回复:** _晚上好！有什么我可以帮助你的吗？_                                                                                 |
| **提示:** _呃，陪我聊聊天？_                                                                                                     |
| **模型回复:** _已完成流式回复: 当然可以！我很乐意陪你聊天。你今天过得怎么样？有什么特别的事情发生吗？或者你有什么想聊的话题吗？_ |

什么嘛，根本就没有沐雪化。低中文语料训练出来的结果就是这样的书面化语气。

或许在未来的一段时间内，国际厂商也能很好地匹配中文的对话语境，但在当下，我们为什么不用效果更好，成本更低廉的国内模型呢？我们的目标又不是证明某个数学定理，只需要有一个匹配我们聊天偏好的 Bot 就可以了。
